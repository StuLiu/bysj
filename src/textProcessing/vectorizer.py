

import re

import jieba.posseg
import config
import os

from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer
def tf_idf_vectoring(content_array):
    """
    :param content_array: è¯„è®ºæ–‡æœ¬æ•°ç»„
    :return: æ ¹æ®tf-idfæ–¹æ³•å‘é‡åŒ–åçš„çŸ©é˜µ
    """
    countVectorizer = CountVectorizer()
    x_counts = countVectorizer.fit_transform(content_array)
    tfidf_transformer = TfidfTransformer()
    x_tfidf = tfidf_transformer.fit_transform(x_counts)
    print("TfidfTransform finished,result shape:",x_tfidf.shape)
    return x_tfidf



class Vectorizer(object):
    """
    ====================================
        Vectorizerï¼šè‡ªå®šä¹‰æ–‡æœ¬å‘é‡åŒ–ç±»
    ====================================
        æ ¹æ®æ•°æ®æ€»ç»“å‡ºï¼šè¯„è®ºidé•¿åº¦ã€è¯„è®ºé•¿åº¦ã€â€˜è¯„è®ºè¯â€™æ¯”ä¾‹ã€è‹±æ–‡æ‰€å æ¯”ä¾‹ã€
    åè¯æ‰€å æ¯”ä¾‹ã€åŠ¨è¯æ‰€å æ¯”ä¾‹ã€å½¢å®¹è¯æ‰€å æ¯”ä¾‹ã€emojiå’Œç‰¹æ®Šå­—ç¬¦æ‰€å æ¯”ä¾‹ã€
    æ„Ÿå¹è¯æ‰€å æ¯”ä¾‹ã€æ•°å­—å’Œé‡è¯æ‰€å æ¯”ä¾‹ã€è¯„è®ºç­‰çº§ç­‰æ•°æ®ä¸ºè¯„è®ºæ–‡æœ¬ç‰¹å¾ã€‚
    """
    def __init__(self):
        # jiebaå¯¼å…¥è‡ªå®šä¹‰è¯å…¸
        jieba.load_userdict(os.path.join(config.DICT_PATH,"user_defined_dict.txt"))
        jieba.load_userdict(os.path.join(config.DICT_PATH,"sogoupinyin_dict.txt"))


    def vectoring(self, comment_id, comment_title, comment_content, comment_rating):
        """
        :param comment_id: è¯„è®ºid
        :param comment_title: è¯„è®ºæ ‡é¢˜
        :param comment_content: è¯„è®ºä¸»è¦å†…å®¹
        :param comment_rating:  è¯„åˆ†ç­‰çº§
        :return vectorizedComment: å‘é‡åŒ–åçš„è¯„è®ºå‘é‡
        """
        punctuation = r'[ï¼!ã€ï¼Œ,ã€‚ï¼š:ï¼›;ï¼Ÿ?â€˜\'â€™â€œ\"â€â€”â€”ï¼ˆï¼‰\(\)ã€ã€‘\[\]\{\}â€¦â€¦\-~`Â·ã€‹ã€Š<>]'
        content_w_counter = len(re.findall(punctuation, comment_content))   #è®¡ç®—æ ‡ç‚¹ç¬¦å·æ•°é‡
        space = r'[\s]'
        words = jieba.posseg.lcut(re.sub(space,'',comment_content,0))   # å»å¤„ç©ºç™½å­—ç¬¦å†åˆ†è¯
        words_len = len(words)
        content_pl_counter = 0
        content_eng_counter = 0
        content_n_counter = 0
        content_v_counter = 0
        content_a_counter = 0
        content_x_counter = 0 - content_w_counter   # jiebaè§†æ ‡ç‚¹ç¬¦å·ä¸ºxç±»å­—ç¬¦ï¼Œ'.'é™¤å¤–
        content_y_counter = 0
        content_m_counter = 0
        for word, flag in words:
            print('%s %s' % (word, flag))
            if flag == 'pl':
                content_pl_counter += 1
            elif flag == 'eng':
                content_eng_counter += 1
            elif flag == 'n' or flag == 'nr' or flag == 'ns' or flag == 'nt' or flag == 'nz':
                content_n_counter += 1
            elif flag == 'vg' or flag == 'v' or flag == 'vd' or flag == 'vn':
                content_v_counter += 1
            elif flag == 'Ag' or flag == 'a' or flag == 'ad' or flag == 'an':
                content_a_counter += 1
            elif flag == 'x':
                content_x_counter += 1
            elif flag == 'y':
                content_y_counter += 1
            elif flag == 'm':
                content_m_counter += 1
            else:
                pass
        vectorizedComment = [
            comment_id,
            len(comment_title),
            len(comment_content),
            float(content_pl_counter) / words_len,
            float(content_eng_counter) / words_len,
            float(content_n_counter) / words_len,
            float(content_v_counter) / words_len,
            float(content_a_counter) / words_len,
            float(content_x_counter) / words_len,
            float(content_w_counter) / words_len,
            float(content_y_counter) / words_len,
            float(content_m_counter) / words_len,
            comment_rating
        ]
        # print(vectorizedComment)
        return vectorizedComment

if __name__ == '__main__':

    contents = [
        "iPhone Xèš‚èšèŠ±å‘—æ‰“å¼€åä¸€ç‰‡ç©ºç™½",
        "ğŸ‘ğŸ‘ã€ä»˜ä¸´é—¨ã€‘ã€è”åˆ·é’±åŒ…ã€‘0.28%ç§’åˆ°ï¼0.28%ç§’åˆ°ï¼åˆ†äº«å•†æœºï¼Œå…±äº«æœªæ¥ï¼åˆ†äº«æ”¯ä»˜ï¼æ”¹å˜æœªæ¥ï¼åˆ†æ¶¦ä¸‡16+2ç§’ç»“ç§’ç»“ï¼æ€»éƒ¨å’¨è¯¢185-1652-4888å¾®ä¿¡åŒå·",
        "æ¯æ¬¡æ‰“å¼€å°±æ˜¯æç¤ºæ›´æ–°çƒ¦ä¸çƒ¦ï¼Ÿä¸æ˜¯æ¯ä¸ªç”¨æˆ·éƒ½éœ€è¦å•¥åŒåäºŒä¼˜æƒ ï¼Œä¸å±‘æ‡‚ä¸ï¼Ÿ",
        "æ£‹ç‰Œæ¸¸æˆå¼€å‘ï¼šL492078507",
        "åªè¦ä¸€éƒ¨æ‰‹æœºğŸ“±ï¼Œèººåœ¨å®¶é‡Œä¹Ÿèƒ½zuan0ğŸŒ¸ğŸ’°â•ä¸ºâ¤615912134",
        "æ”¯ä»˜å®æ¨èï¼å…³æ³¨VXå…±ä¼—è™Ÿã€swapp321ã€‘æ‰‹æœ¨å‡ è½¬RMï¿¥ï¼Œå½“å¤©è¿›å£è¢‹è´°ä½°åœ†ï¼",
        "rt æ— åŠ›åæ§½sbé©¬äº‘",
        "    s  è†œæ‹œå•è½¦æ‘©æ‹œå•è½¦â¤â¤ ",
        "Very useful!thanks a lot",
        "å•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå“¦å•Šå•Šå•Šå•Šå‘€å‘€å‘€å‘ƒå‘ƒå‘ƒå“¦å“¦å“¦å’¦55555555å’¦",
        "!?ï¼Ÿã€‚ã€\'\"{}[]ã€ã€‘.å•Š"
    ]
    sign = []
    vectorizer = Vectorizer()
    for content in contents:
        vectorizer.vectoring("comment_id","comment_title",content,0)

    tf_idf_vectoring(contents)

